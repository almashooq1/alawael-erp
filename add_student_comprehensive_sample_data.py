#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ø´Ø§Ù…Ù„Ø© Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ø·Ø§Ù„Ø¨
Sample Data for Student Comprehensive File System
"""

import sys
import os
from datetime import datetime, timedelta
import random
from decimal import Decimal

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app import app, db
from models import User, Student
from student_comprehensive_models import (
    ComprehensiveStudentFile, AssessmentTemplate, AssessmentRecord,
    AIAnalysisResult, FileExportLog, FileImportLog, PrintJob
)

def add_sample_data():
    """Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ø´Ø§Ù…Ù„Ø©"""
    
    with app.app_context():
        try:
            print("ğŸš€ Ø¨Ø¯Ø¡ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ø·Ø§Ù„Ø¨...")
            
            # 1. Ø¥Ù†Ø´Ø§Ø¡ Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
            templates = create_assessment_templates()
            print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(templates)} Ù‚Ø§Ù„Ø¨ ØªÙ‚ÙŠÙŠÙ…")
            
            # 2. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø·Ù„Ø§Ø¨
            files = create_comprehensive_files()
            print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(files)} Ù…Ù„Ù Ø´Ø§Ù…Ù„")
            
            # 3. Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
            assessments = create_assessment_records(templates, files)
            print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(assessments)} Ø³Ø¬Ù„ ØªÙ‚ÙŠÙŠÙ…")
            
            # 4. Ø¥Ù†Ø´Ø§Ø¡ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
            ai_results = create_ai_analysis_results(assessments)
            print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(ai_results)} Ù†ØªÙŠØ¬Ø© ØªØ­Ù„ÙŠÙ„ Ø°ÙƒÙŠ")
            
            # 5. Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØµØ¯ÙŠØ± ÙˆØ§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
            export_logs, import_logs = create_export_import_logs(files)
            print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(export_logs)} Ø³Ø¬Ù„ ØªØµØ¯ÙŠØ± Ùˆ {len(import_logs)} Ø³Ø¬Ù„ Ø§Ø³ØªÙŠØ±Ø§Ø¯")
            
            # 6. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‡Ø§Ù… Ø§Ù„Ø·Ø¨Ø§Ø¹Ø©
            print_jobs = create_print_jobs(files)
            print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(print_jobs)} Ù…Ù‡Ù…Ø© Ø·Ø¨Ø§Ø¹Ø©")
            
            db.session.commit()
            print("ğŸ‰ ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!")
            
            # Ø·Ø¨Ø§Ø¹Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            print_statistics()
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            db.session.rollback()
            raise

def create_assessment_templates():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…"""
    templates_data = [
        {
            'name': 'ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø­Ø±ÙƒÙŠØ©',
            'description': 'ØªÙ‚ÙŠÙŠÙ… Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø­Ø±ÙƒÙŠØ© Ø§Ù„ÙƒØ¨Ø±Ù‰ ÙˆØ§Ù„Ø¯Ù‚ÙŠÙ‚Ø©',
            'category': 'motor_skills',
            'sections': {
                'gross_motor': 'Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø­Ø±ÙƒÙŠØ© Ø§Ù„ÙƒØ¨Ø±Ù‰',
                'fine_motor': 'Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø­Ø±ÙƒÙŠØ© Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©',
                'coordination': 'Ø§Ù„ØªÙ†Ø§Ø³Ù‚ ÙˆØ§Ù„ØªÙˆØ§Ø²Ù†'
            },
            'scoring_method': 'scale_1_5',
            'max_score': 100,
            'passing_score': 70
        },
        {
            'name': 'ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¹Ø±ÙÙŠØ©',
            'description': 'ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ù…Ø¹Ø±ÙÙŠØ© ÙˆØ§Ù„Ø°Ù‡Ù†ÙŠØ©',
            'category': 'cognitive_skills',
            'sections': {
                'attention': 'Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ ÙˆØ§Ù„ØªØ±ÙƒÙŠØ²',
                'memory': 'Ø§Ù„Ø°Ø§ÙƒØ±Ø©',
                'problem_solving': 'Ø­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø§Øª'
            },
            'scoring_method': 'percentage',
            'max_score': 100,
            'passing_score': 65
        },
        {
            'name': 'ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©',
            'description': 'ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªÙØ§Ø¹Ù„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ ÙˆØ§Ù„ØªÙˆØ§ØµÙ„',
            'category': 'social_skills',
            'sections': {
                'communication': 'Ø§Ù„ØªÙˆØ§ØµÙ„',
                'interaction': 'Ø§Ù„ØªÙØ§Ø¹Ù„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ',
                'behavior': 'Ø§Ù„Ø³Ù„ÙˆÙƒ'
            },
            'scoring_method': 'scale_1_10',
            'max_score': 100,
            'passing_score': 60
        }
    ]
    
    templates = []
    for data in templates_data:
        template = AssessmentTemplate(
            name=data['name'],
            description=data['description'],
            category=data['category'],
            sections=data['sections'],
            scoring_method=data['scoring_method'],
            max_score=data['max_score'],
            passing_score=data['passing_score'],
            is_active=True,
            created_by=1
        )
        db.session.add(template)
        templates.append(template)
    
    db.session.flush()
    return templates

def create_comprehensive_files():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø·Ù„Ø§Ø¨"""
    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø·Ù„Ø§Ø¨ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ÙŠÙ†
    students = Student.query.limit(10).all()
    if not students:
        print("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø·Ù„Ø§Ø¨ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…ØŒ Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©")
        return []
    
    files = []
    for i, student in enumerate(students):
        file_data = {
            'student_id': student.id,
            'file_number': f'CF-{2024}-{str(i+1).zfill(4)}',
            'personal_info': {
                'full_name': student.name,
                'birth_date': '2010-01-15',
                'gender': 'male' if i % 2 == 0 else 'female',
                'nationality': 'Ø³Ø¹ÙˆØ¯ÙŠ',
                'id_number': f'1234567890{i}'
            },
            'medical_info': {
                'diagnosis': 'Ø§Ø¶Ø·Ø±Ø§Ø¨ Ø·ÙŠÙ Ø§Ù„ØªÙˆØ­Ø¯' if i % 3 == 0 else 'ØªØ£Ø®Ø± ÙÙŠ Ø§Ù„Ù†Ù…Ùˆ',
                'medications': ['Ø¯ÙˆØ§Ø¡ ØªØ¬Ø±ÙŠØ¨ÙŠ 1', 'Ø¯ÙˆØ§Ø¡ ØªØ¬Ø±ÙŠØ¨ÙŠ 2'],
                'allergies': ['Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„ÙÙˆÙ„ Ø§Ù„Ø³ÙˆØ¯Ø§Ù†ÙŠ'] if i % 4 == 0 else [],
                'medical_history': 'ØªØ§Ø±ÙŠØ® Ø·Ø¨ÙŠ Ø·Ø¨ÙŠØ¹ÙŠ'
            },
            'family_info': {
                'father_name': f'ÙˆØ§Ù„Ø¯ Ø§Ù„Ø·Ø§Ù„Ø¨ {i+1}',
                'mother_name': f'ÙˆØ§Ù„Ø¯Ø© Ø§Ù„Ø·Ø§Ù„Ø¨ {i+1}',
                'contact_phone': f'05{random.randint(10000000, 99999999)}',
                'address': f'Ø§Ù„Ø±ÙŠØ§Ø¶ØŒ Ø­ÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠØŒ Ø´Ø§Ø±Ø¹ {i+1}'
            },
            'educational_background': {
                'previous_schools': ['Ù…Ø¯Ø±Ø³Ø© ØªØ¬Ø±ÙŠØ¨ÙŠØ©'],
                'current_level': f'Ø§Ù„ØµÙ {random.randint(1, 6)}',
                'special_needs': True,
                'iep_status': 'active'
            }
        }
        
        comprehensive_file = ComprehensiveStudentFile(
            student_id=file_data['student_id'],
            file_number=file_data['file_number'],
            personal_info=file_data['personal_info'],
            medical_info=file_data['medical_info'],
            family_info=file_data['family_info'],
            educational_background=file_data['educational_background'],
            status='active',
            created_by=1
        )
        
        db.session.add(comprehensive_file)
        files.append(comprehensive_file)
    
    db.session.flush()
    return files

def create_assessment_records(templates, files):
    """Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªÙ‚ÙŠÙŠÙ…"""
    assessments = []
    
    for file in files:
        for template in templates:
            # Ø¥Ù†Ø´Ø§Ø¡ 2-3 ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ù„ÙƒÙ„ Ø·Ø§Ù„Ø¨ ÙÙŠ ÙƒÙ„ Ù‚Ø§Ù„Ø¨
            for j in range(random.randint(2, 3)):
                assessment_date = datetime.now() - timedelta(days=random.randint(30, 365))
                
                # Ù†ØªØ§Ø¦Ø¬ ØªØ¬Ø±ÙŠØ¨ÙŠØ©
                results = {}
                total_score = 0
                section_count = len(template.sections)
                
                for section_key in template.sections.keys():
                    section_score = random.randint(50, 95)
                    results[section_key] = {
                        'score': section_score,
                        'notes': f'Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø¹Ù„Ù‰ {template.sections[section_key]}',
                        'recommendations': [f'ØªÙˆØµÙŠØ© 1 Ù„Ù€ {section_key}', f'ØªÙˆØµÙŠØ© 2 Ù„Ù€ {section_key}']
                    }
                    total_score += section_score
                
                final_score = total_score / section_count if section_count > 0 else 0
                
                assessment = AssessmentRecord(
                    comprehensive_file_id=file.id,
                    template_id=template.id,
                    assessment_date=assessment_date,
                    assessor_name=f'Ø§Ù„Ù…Ù‚ÙŠÙ… {random.randint(1, 5)}',
                    results=results,
                    total_score=Decimal(str(round(final_score, 2))),
                    notes=f'Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø±Ù‚Ù… {j+1}',
                    recommendations=['ØªÙˆØµÙŠØ© Ø¹Ø§Ù…Ø© 1', 'ØªÙˆØµÙŠØ© Ø¹Ø§Ù…Ø© 2'],
                    status='completed',
                    created_by=1
                )
                
                db.session.add(assessment)
                assessments.append(assessment)
    
    db.session.flush()
    return assessments

def create_ai_analysis_results(assessments):
    """Ø¥Ù†Ø´Ø§Ø¡ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
    ai_results = []
    
    analysis_types = ['performance_analysis', 'pattern_detection', 'progress_prediction', 'recommendation_generation']
    
    for assessment in assessments[:20]:  # ØªØ­Ù„ÙŠÙ„ Ø£ÙˆÙ„ 20 ØªÙ‚ÙŠÙŠÙ…
        analysis_type = random.choice(analysis_types)
        
        # Ù†ØªØ§Ø¦Ø¬ ØªØ­Ù„ÙŠÙ„ ØªØ¬Ø±ÙŠØ¨ÙŠØ©
        analysis_results = {
            'strengths': ['Ù†Ù‚Ø·Ø© Ù‚ÙˆØ© 1', 'Ù†Ù‚Ø·Ø© Ù‚ÙˆØ© 2'],
            'weaknesses': ['Ù†Ù‚Ø·Ø© Ø¶Ø¹Ù 1', 'Ù†Ù‚Ø·Ø© Ø¶Ø¹Ù 2'],
            'patterns': ['Ù†Ù…Ø· 1', 'Ù†Ù…Ø· 2'],
            'predictions': {
                'short_term': 'ØªØ­Ø³Ù† Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„Ù…Ø¯Ù‰ Ø§Ù„Ù‚ØµÙŠØ±',
                'long_term': 'ØªØ·ÙˆØ± Ø¥ÙŠØ¬Ø§Ø¨ÙŠ ÙÙŠ Ø§Ù„Ù…Ø¯Ù‰ Ø§Ù„Ø·ÙˆÙŠÙ„'
            },
            'recommendations': ['ØªÙˆØµÙŠØ© Ø°ÙƒÙŠØ© 1', 'ØªÙˆØµÙŠØ© Ø°ÙƒÙŠØ© 2']
        }
        
        ai_result = AIAnalysisResult(
            assessment_record_id=assessment.id,
            analysis_type=analysis_type,
            analysis_results=analysis_results,
            confidence_score=Decimal(str(random.uniform(0.7, 0.95))),
            insights=['Ø±Ø¤ÙŠØ© 1', 'Ø±Ø¤ÙŠØ© 2'],
            recommendations=['ØªÙˆØµÙŠØ© AI 1', 'ØªÙˆØµÙŠØ© AI 2'],
            status='completed',
            created_by=1
        )
        
        db.session.add(ai_result)
        ai_results.append(ai_result)
    
    db.session.flush()
    return ai_results

def create_export_import_logs(files):
    """Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØµØ¯ÙŠØ± ÙˆØ§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯"""
    export_logs = []
    import_logs = []
    
    # Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØµØ¯ÙŠØ±
    for i, file in enumerate(files[:5]):
        export_log = FileExportLog(
            comprehensive_file_id=file.id,
            export_format=random.choice(['pdf', 'excel', 'json']),
            sections_included=['personal_info', 'assessments', 'ai_analysis'],
            file_path=f'/exports/student_{file.id}_export_{i+1}.pdf',
            file_size=random.randint(500000, 2000000),
            status='completed',
            exported_by=1
        )
        db.session.add(export_log)
        export_logs.append(export_log)
    
    # Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
    for i in range(3):
        import_log = FileImportLog(
            source_file_path=f'/imports/import_file_{i+1}.json',
            import_type=random.choice(['new_file', 'update_existing', 'merge_data']),
            records_processed=random.randint(5, 20),
            records_successful=random.randint(4, 18),
            records_failed=random.randint(0, 2),
            validation_errors={'errors': ['Ø®Ø·Ø£ ØªØ¬Ø±ÙŠØ¨ÙŠ 1', 'Ø®Ø·Ø£ ØªØ¬Ø±ÙŠØ¨ÙŠ 2']},
            status='completed',
            imported_by=1
        )
        db.session.add(import_log)
        import_logs.append(import_log)
    
    db.session.flush()
    return export_logs, import_logs

def create_print_jobs(files):
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‡Ø§Ù… Ø§Ù„Ø·Ø¨Ø§Ø¹Ø©"""
    print_jobs = []
    
    for i, file in enumerate(files[:7]):
        print_job = PrintJob(
            comprehensive_file_id=file.id,
            print_type=random.choice(['full_file', 'assessments_only', 'summary_report']),
            sections_to_print=['personal_info', 'assessments'],
            printer_name=f'Ø·Ø§Ø¨Ø¹Ø© Ø§Ù„Ù…ÙƒØªØ¨ {random.randint(1, 3)}',
            copies_count=random.randint(1, 3),
            paper_size='A4',
            is_confidential=random.choice([True, False]),
            status=random.choice(['pending', 'printing', 'completed']),
            created_by=1
        )
        
        if print_job.status == 'completed':
            print_job.completed_at = datetime.now() - timedelta(hours=random.randint(1, 48))
        
        db.session.add(print_job)
        print_jobs.append(print_job)
    
    db.session.flush()
    return print_jobs

def print_statistics():
    """Ø·Ø¨Ø§Ø¹Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¶Ø§ÙØ©"""
    print("\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¶Ø§ÙØ©:")
    print(f"   ğŸ“‹ Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {AssessmentTemplate.query.count()}")
    print(f"   ğŸ“ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©: {ComprehensiveStudentFile.query.count()}")
    print(f"   ğŸ“ Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {AssessmentRecord.query.count()}")
    print(f"   ğŸ¤– Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ: {AIAnalysisResult.query.count()}")
    print(f"   ğŸ“¤ Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØµØ¯ÙŠØ±: {FileExportLog.query.count()}")
    print(f"   ğŸ“¥ Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯: {FileImportLog.query.count()}")
    print(f"   ğŸ–¨ï¸ Ù…Ù‡Ø§Ù… Ø§Ù„Ø·Ø¨Ø§Ø¹Ø©: {PrintJob.query.count()}")

if __name__ == '__main__':
    add_sample_data()
