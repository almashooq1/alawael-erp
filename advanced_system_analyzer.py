#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ù…Ø­Ù„Ù„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù… - ÙØ­Øµ Ø¯Ù‚ÙŠÙ‚ ÙˆØ´Ø§Ù…Ù„ Ù„Ø¬Ù…ÙŠØ¹ Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
"""

import os
import ast
import re
import json
import sqlite3
from datetime import datetime
from collections import defaultdict, Counter
import traceback

class AdvancedSystemAnalyzer:
    def __init__(self):
        self.report = {
            'timestamp': datetime.now().isoformat(),
            'summary': {},
            'files': {},
            'database': {},
            'models': {},
            'imports': {},
            'relationships': {},
            'issues': [],
            'warnings': [],
            'recommendations': [],
            'statistics': {}
        }
        
    def analyze_python_files(self):
        """ØªØ­Ù„ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Python"""
        print("ğŸ” ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª Python...")
        
        python_files = []
        for root, dirs, files in os.walk('.'):
            # ØªØ¬Ø§Ù‡Ù„ Ù…Ø¬Ù„Ø¯Ø§Øª Ù…Ø¹ÙŠÙ†Ø©
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'venv', '.venv', 'node_modules']]
            
            for file in files:
                if file.endswith('.py'):
                    file_path = os.path.join(root, file)
                    python_files.append(file_path)
        
        total_files = len(python_files)
        syntax_errors = 0
        import_errors = 0
        total_lines = 0
        
        for file_path in python_files:
            file_info = self.analyze_single_file(file_path)
            self.report['files'][file_path] = file_info
            
            if not file_info['syntax_valid']:
                syntax_errors += 1
            if file_info['import_issues']:
                import_errors += 1
            total_lines += file_info['line_count']
        
        self.report['statistics']['python_files'] = {
            'total': total_files,
            'syntax_errors': syntax_errors,
            'import_errors': import_errors,
            'total_lines': total_lines,
            'average_lines': total_lines / total_files if total_files > 0 else 0
        }
        
        print(f"  ğŸ“Š ØªÙ… ØªØ­Ù„ÙŠÙ„ {total_files} Ù…Ù„Ù Python")
        print(f"  âŒ Ø£Ø®Ø·Ø§Ø¡ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ù…Ù„Ø©: {syntax_errors}")
        print(f"  âš ï¸ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯: {import_errors}")
        print(f"  ğŸ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø³Ø·Ø±: {total_lines:,}")
        
        return total_files, syntax_errors, import_errors
    
    def analyze_single_file(self, file_path):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù ÙˆØ§Ø­Ø¯ Ø¨Ø§Ù„ØªÙØµÙŠÙ„"""
        file_info = {
            'path': file_path,
            'size': 0,
            'line_count': 0,
            'syntax_valid': False,
            'imports': [],
            'classes': [],
            'functions': [],
            'import_issues': [],
            'complexity_score': 0,
            'docstring_coverage': 0
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            file_info['size'] = len(content)
            file_info['line_count'] = len(content.split('\n'))
            
            # ÙØ­Øµ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ù…Ù„Ø©
            try:
                tree = ast.parse(content)
                file_info['syntax_valid'] = True
                
                # ØªØ­Ù„ÙŠÙ„ AST
                self.analyze_ast(tree, file_info)
                
            except SyntaxError as e:
                file_info['syntax_valid'] = False
                self.report['issues'].append({
                    'type': 'SYNTAX_ERROR',
                    'file': file_path,
                    'line': e.lineno,
                    'message': str(e)
                })
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª
            self.analyze_imports(content, file_info)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
            file_info['complexity_score'] = self.calculate_complexity(content)
            
            # ÙØ­Øµ Ø§Ù„ØªÙˆØ«ÙŠÙ‚
            file_info['docstring_coverage'] = self.check_docstring_coverage(content)
            
        except Exception as e:
            self.report['issues'].append({
                'type': 'FILE_READ_ERROR',
                'file': file_path,
                'message': str(e)
            })
        
        return file_info
    
    def analyze_ast(self, tree, file_info):
        """ØªØ­Ù„ÙŠÙ„ Ø´Ø¬Ø±Ø© AST"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                file_info['classes'].append({
                    'name': node.name,
                    'line': node.lineno,
                    'methods': len([n for n in node.body if isinstance(n, ast.FunctionDef)])
                })
            elif isinstance(node, ast.FunctionDef):
                file_info['functions'].append({
                    'name': node.name,
                    'line': node.lineno,
                    'args': len(node.args.args)
                })
    
    def analyze_imports(self, content, file_info):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª"""
        import_pattern = r'^(from\s+\S+\s+import\s+.+|import\s+.+)$'
        
        for line_num, line in enumerate(content.split('\n'), 1):
            line = line.strip()
            if re.match(import_pattern, line):
                file_info['imports'].append({
                    'line': line_num,
                    'statement': line
                })
    
    def calculate_complexity(self, content):
        """Ø­Ø³Ø§Ø¨ ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯"""
        complexity = 0
        
        # Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø±ÙˆØ· ÙˆØ§Ù„Ø­Ù„Ù‚Ø§Øª
        complexity += len(re.findall(r'\b(if|elif|for|while|try|except)\b', content))
        
        # Ø¹Ø¯Ø¯ Ø§Ù„Ø¯ÙˆØ§Ù„ ÙˆØ§Ù„ÙƒÙ„Ø§Ø³Ø§Øª
        complexity += len(re.findall(r'\b(def|class)\b', content))
        
        # Ø·ÙˆÙ„ Ø§Ù„Ø£Ø³Ø·Ø±
        lines = content.split('\n')
        long_lines = sum(1 for line in lines if len(line) > 100)
        complexity += long_lines * 0.1
        
        return round(complexity, 2)
    
    def check_docstring_coverage(self, content):
        """ÙØ­Øµ ØªØºØ·ÙŠØ© Ø§Ù„ØªÙˆØ«ÙŠÙ‚"""
        try:
            tree = ast.parse(content)
            total_items = 0
            documented_items = 0
            
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
                    total_items += 1
                    if ast.get_docstring(node):
                        documented_items += 1
            
            return (documented_items / total_items * 100) if total_items > 0 else 0
        except:
            return 0
    
    def analyze_database_models(self):
        """ØªØ­Ù„ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        print("ğŸ” ØªØ­Ù„ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
        
        if not os.path.exists('models.py'):
            self.report['issues'].append({
                'type': 'MISSING_FILE',
                'file': 'models.py',
                'message': 'Ù…Ù„Ù Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯'
            })
            return
        
        try:
            with open('models.py', 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            models = self.extract_models(content)
            self.report['models'] = models
            
            # ÙØ­Øµ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª
            relationships = self.analyze_relationships(content)
            self.report['relationships'] = relationships
            
            # ÙØ­Øµ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
            duplicate_backrefs = self.find_duplicate_backrefs(content)
            if duplicate_backrefs:
                for backref, count in duplicate_backrefs.items():
                    self.report['issues'].append({
                        'type': 'DUPLICATE_BACKREF',
                        'file': 'models.py',
                        'message': f"Ø¹Ù„Ø§Ù‚Ø© Ù…ÙƒØ±Ø±Ø©: '{backref}' ({count} Ù…Ø±Ø§Øª)"
                    })
            
            print(f"  ğŸ“Š ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(models)} Ù†Ù…ÙˆØ°Ø¬")
            print(f"  ğŸ”— ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(relationships)} Ø¹Ù„Ø§Ù‚Ø©")
            
        except Exception as e:
            self.report['issues'].append({
                'type': 'MODEL_ANALYSIS_ERROR',
                'file': 'models.py',
                'message': str(e)
            })
    
    def extract_models(self, content):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ù† Ø§Ù„ÙƒÙˆØ¯"""
        models = {}
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØªØ¹Ø±ÙŠÙØ§Øª Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª
        class_pattern = r'class\s+(\w+)\(db\.Model\):'
        matches = re.finditer(class_pattern, content)
        
        for match in matches:
            model_name = match.group(1)
            start_pos = match.start()
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒÙ„Ø§Ø³
            model_content = self.extract_class_content(content, start_pos)
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ù‚ÙˆÙ„
            fields = self.extract_model_fields(model_content)
            
            models[model_name] = {
                'name': model_name,
                'fields': fields,
                'field_count': len(fields),
                'has_primary_key': any(f.get('primary_key') for f in fields),
                'has_timestamps': any('created_at' in f['name'] or 'updated_at' in f['name'] for f in fields)
            }
        
        return models
    
    def extract_class_content(self, content, start_pos):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒÙ„Ø§Ø³"""
        lines = content[start_pos:].split('\n')
        class_lines = [lines[0]]  # Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø£ÙˆÙ„ (ØªØ¹Ø±ÙŠÙ Ø§Ù„ÙƒÙ„Ø§Ø³)
        
        for line in lines[1:]:
            if line.strip() and not line.startswith(' ') and not line.startswith('\t'):
                break  # Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ÙƒÙ„Ø§Ø³
            class_lines.append(line)
        
        return '\n'.join(class_lines)
    
    def extract_model_fields(self, model_content):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        fields = []
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØªØ¹Ø±ÙŠÙØ§Øª Ø§Ù„Ø­Ù‚ÙˆÙ„
        field_pattern = r'(\w+)\s*=\s*db\.Column\(([^)]+)\)'
        matches = re.finditer(field_pattern, model_content)
        
        for match in matches:
            field_name = match.group(1)
            field_definition = match.group(2)
            
            field_info = {
                'name': field_name,
                'definition': field_definition,
                'primary_key': 'primary_key=True' in field_definition,
                'nullable': 'nullable=False' not in field_definition,
                'unique': 'unique=True' in field_definition
            }
            
            fields.append(field_info)
        
        return fields
    
    def analyze_relationships(self, content):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª"""
        relationships = []
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª
        relationship_pattern = r'(\w+)\s*=\s*db\.relationship\([^)]+\)'
        matches = re.finditer(relationship_pattern, content)
        
        for match in matches:
            rel_name = match.group(1)
            rel_definition = match.group(0)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ backref
            backref_match = re.search(r"backref='([^']+)'", rel_definition)
            backref = backref_match.group(1) if backref_match else None
            
            relationships.append({
                'name': rel_name,
                'definition': rel_definition,
                'backref': backref
            })
        
        return relationships
    
    def find_duplicate_backrefs(self, content):
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©"""
        backref_pattern = r"backref='([^']+)'"
        matches = re.findall(backref_pattern, content)
        
        backref_counts = Counter(matches)
        return {k: v for k, v in backref_counts.items() if v > 1}
    
    def analyze_database_file(self):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        print("ğŸ” ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        db_files = []
        for file in os.listdir('.'):
            if file.endswith('.db') or file.endswith('.sqlite') or file.endswith('.sqlite3'):
                db_files.append(file)
        
        if not db_files:
            self.report['warnings'].append({
                'type': 'NO_DATABASE_FILE',
                'message': 'Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª'
            })
            return
        
        for db_file in db_files:
            try:
                conn = sqlite3.connect(db_file)
                cursor = conn.cursor()
                
                # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
                tables = cursor.fetchall()
                
                db_info = {
                    'file': db_file,
                    'size': os.path.getsize(db_file),
                    'tables': []
                }
                
                for table in tables:
                    table_name = table[0]
                    
                    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„
                    cursor.execute(f"PRAGMA table_info({table_name});")
                    columns = cursor.fetchall()
                    
                    cursor.execute(f"SELECT COUNT(*) FROM {table_name};")
                    row_count = cursor.fetchone()[0]
                    
                    db_info['tables'].append({
                        'name': table_name,
                        'columns': len(columns),
                        'rows': row_count,
                        'column_details': columns
                    })
                
                self.report['database'][db_file] = db_info
                conn.close()
                
                print(f"  ğŸ“Š Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {db_file}")
                print(f"  ğŸ“‹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„: {len(tables)}")
                
            except Exception as e:
                self.report['issues'].append({
                    'type': 'DATABASE_ERROR',
                    'file': db_file,
                    'message': str(e)
                })
    
    def analyze_static_files(self):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø«Ø§Ø¨ØªØ©"""
        print("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø«Ø§Ø¨ØªØ©...")
        
        static_info = {
            'css_files': [],
            'js_files': [],
            'html_files': [],
            'image_files': [],
            'other_files': []
        }
        
        # ÙØ­Øµ Ù…Ø¬Ù„Ø¯ static
        if os.path.exists('static'):
            for root, dirs, files in os.walk('static'):
                for file in files:
                    file_path = os.path.join(root, file)
                    file_size = os.path.getsize(file_path)
                    
                    file_info = {
                        'path': file_path,
                        'size': file_size
                    }
                    
                    if file.endswith('.css'):
                        static_info['css_files'].append(file_info)
                    elif file.endswith('.js'):
                        static_info['js_files'].append(file_info)
                    elif file.endswith(('.png', '.jpg', '.jpeg', '.gif', '.svg')):
                        static_info['image_files'].append(file_info)
                    else:
                        static_info['other_files'].append(file_info)
        
        # ÙØ­Øµ Ù…Ø¬Ù„Ø¯ templates
        if os.path.exists('templates'):
            for root, dirs, files in os.walk('templates'):
                for file in files:
                    if file.endswith('.html'):
                        file_path = os.path.join(root, file)
                        file_size = os.path.getsize(file_path)
                        static_info['html_files'].append({
                            'path': file_path,
                            'size': file_size
                        })
        
        self.report['static_files'] = static_info
        
        total_static = (len(static_info['css_files']) + len(static_info['js_files']) + 
                       len(static_info['html_files']) + len(static_info['image_files']) + 
                       len(static_info['other_files']))
        
        print(f"  ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø«Ø§Ø¨ØªØ©: {total_static}")
        print(f"  ğŸ¨ Ù…Ù„ÙØ§Øª CSS: {len(static_info['css_files'])}")
        print(f"  ğŸ“œ Ù…Ù„ÙØ§Øª JavaScript: {len(static_info['js_files'])}")
        print(f"  ğŸ“„ Ù…Ù„ÙØ§Øª HTML: {len(static_info['html_files'])}")
        print(f"  ğŸ–¼ï¸ Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØ±: {len(static_info['image_files'])}")
    
    def generate_recommendations(self):
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
        print("ğŸ’¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª...")
        
        recommendations = []
        
        # ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
        syntax_errors = len([i for i in self.report['issues'] if i['type'] == 'SYNTAX_ERROR'])
        if syntax_errors > 0:
            recommendations.append({
                'priority': 'HIGH',
                'category': 'CODE_QUALITY',
                'message': f'Ø¥ØµÙ„Ø§Ø­ {syntax_errors} Ø®Ø·Ø£ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ù…Ù„Ø©'
            })
        
        # ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
        duplicate_backrefs = len([i for i in self.report['issues'] if i['type'] == 'DUPLICATE_BACKREF'])
        if duplicate_backrefs > 0:
            recommendations.append({
                'priority': 'HIGH',
                'category': 'DATABASE',
                'message': f'Ø¥ØµÙ„Ø§Ø­ {duplicate_backrefs} Ø¹Ù„Ø§Ù‚Ø© Ù…ÙƒØ±Ø±Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª'
            })
        
        # ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆØ«ÙŠÙ‚
        if self.report['files']:
            avg_docstring = sum(f.get('docstring_coverage', 0) for f in self.report['files'].values()) / len(self.report['files'])
            if avg_docstring < 50:
                recommendations.append({
                    'priority': 'MEDIUM',
                    'category': 'DOCUMENTATION',
                    'message': f'ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙˆØ«ÙŠÙ‚ - Ø§Ù„ØªØºØ·ÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {avg_docstring:.1f}%'
                })
        
        # ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
        if self.report['files']:
            high_complexity_files = [f for f in self.report['files'].values() if f.get('complexity_score', 0) > 20]
            if high_complexity_files:
                recommendations.append({
                    'priority': 'MEDIUM',
                    'category': 'CODE_QUALITY',
                    'message': f'ØªØ¨Ø³ÙŠØ· {len(high_complexity_files)} Ù…Ù„Ù Ù…Ø¹Ù‚Ø¯'
                })
        
        self.report['recommendations'] = recommendations
        
        for rec in recommendations:
            priority_icon = "ğŸ”´" if rec['priority'] == 'HIGH' else "ğŸŸ¡" if rec['priority'] == 'MEDIUM' else "ğŸŸ¢"
            print(f"  {priority_icon} {rec['message']}")
    
    def generate_summary(self):
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù„Ø®Øµ"""
        stats = self.report['statistics']
        
        total_issues = len(self.report['issues'])
        total_warnings = len(self.report['warnings'])
        total_recommendations = len(self.report['recommendations'])
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¹Ø§Ù…Ø©
        max_score = 100
        score = max_score
        
        # Ø®ØµÙ… Ù†Ù‚Ø§Ø· Ù„Ù„Ø£Ø®Ø·Ø§Ø¡
        score -= total_issues * 10
        score -= total_warnings * 5
        
        # Ø®ØµÙ… Ù†Ù‚Ø§Ø· Ù„Ù„ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø¹Ø§Ù„ÙŠ
        if self.report['files']:
            avg_complexity = sum(f.get('complexity_score', 0) for f in self.report['files'].values()) / len(self.report['files'])
            if avg_complexity > 15:
                score -= 10
        
        score = max(0, score)  # Ù„Ø§ ØªÙ‚Ù„ Ø¹Ù† ØµÙØ±
        
        self.report['summary'] = {
            'overall_score': score,
            'health_status': 'Ù…Ù…ØªØ§Ø²' if score >= 90 else 'Ø¬ÙŠØ¯' if score >= 70 else 'ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†' if score >= 50 else 'ÙŠØ­ØªØ§Ø¬ Ø¥ØµÙ„Ø§Ø­ Ø¹Ø§Ø¬Ù„',
            'total_files': stats.get('python_files', {}).get('total', 0),
            'total_issues': total_issues,
            'total_warnings': total_warnings,
            'total_recommendations': total_recommendations,
            'models_count': len(self.report['models']),
            'relationships_count': len(self.report['relationships'])
        }
    
    def save_report(self, filename='system_analysis_report.json'):
        """Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ: {filename}")
    
    def print_detailed_report(self):
        """Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…ÙØµÙ„"""
        print("\n" + "=" * 80)
        print("ğŸ“‹ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ù†Ø¸Ø§Ù…")
        print("=" * 80)
        
        summary = self.report['summary']
        
        print(f"ğŸ¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¹Ø§Ù…Ø©: {summary['overall_score']}/100")
        print(f"ğŸ“Š Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {summary['health_status']}")
        print(f"ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ù„ÙŠÙ„: {self.report['timestamp']}")
        
        print(f"\nğŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª:")
        print(f"  ğŸ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª: {summary['total_files']}")
        print(f"  ğŸ—ï¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {summary['models_count']}")
        print(f"  ğŸ”— Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª: {summary['relationships_count']}")
        print(f"  âŒ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„: {summary['total_issues']}")
        print(f"  âš ï¸ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª: {summary['total_warnings']}")
        print(f"  ğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª: {summary['total_recommendations']}")
        
        # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø­Ø±Ø¬Ø©
        if self.report['issues']:
            print(f"\nâŒ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø­Ø±Ø¬Ø©:")
            for issue in self.report['issues'][:10]:  # Ø£ÙˆÙ„ 10 Ù…Ø´Ø§ÙƒÙ„
                print(f"  - {issue['type']}: {issue['message']}")
                if 'file' in issue:
                    print(f"    Ø§Ù„Ù…Ù„Ù: {issue['file']}")
        
        # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª
        if self.report['recommendations']:
            print(f"\nğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª:")
            for rec in self.report['recommendations']:
                priority_icon = "ğŸ”´" if rec['priority'] == 'HIGH' else "ğŸŸ¡" if rec['priority'] == 'MEDIUM' else "ğŸŸ¢"
                print(f"  {priority_icon} {rec['message']}")
        
        print(f"\nğŸ“„ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙƒØ§Ù…Ù„ ÙÙŠ: system_analysis_report.json")
    
    def run_complete_analysis(self):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„"""
        print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ù†Ø¸Ø§Ù…...")
        print("=" * 60)
        
        try:
            # ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª Python
            self.analyze_python_files()
            
            # ØªØ­Ù„ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            self.analyze_database_models()
            
            # ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            self.analyze_database_file()
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø«Ø§Ø¨ØªØ©
            self.analyze_static_files()
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª
            self.generate_recommendations()
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù„Ø®Øµ
            self.generate_summary()
            
            # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
            self.save_report()
            
            # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ±
            self.print_detailed_report()
            
            return True
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}")
            traceback.print_exc()
            return False

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    analyzer = AdvancedSystemAnalyzer()
    success = analyzer.run_complete_analysis()
    
    if success:
        print(f"\nğŸ‰ ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
    else:
        print(f"\nâŒ ÙØ´Ù„ ÙÙŠ Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
    
    return success

if __name__ == "__main__":
    main()
