#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ÙØµÙ„ - ÙØ­Øµ Ø¯Ù‚ÙŠÙ‚ ÙˆØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„
"""

import os
import ast
import re
from datetime import datetime
from collections import defaultdict, Counter

def check_syntax_errors():
    """ÙØ­Øµ Ø£Ø®Ø·Ø§Ø¡ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ù…Ù„Ø©"""
    print("ğŸ” ÙØ­Øµ Ø£Ø®Ø·Ø§Ø¡ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ù…Ù„Ø©...")
    
    python_files = [f for f in os.listdir('.') if f.endswith('.py')]
    syntax_errors = []
    valid_files = []
    
    for file_path in python_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            ast.parse(content)
            valid_files.append(file_path)
        except SyntaxError as e:
            syntax_errors.append({
                'file': file_path,
                'line': e.lineno,
                'error': str(e)
            })
        except Exception as e:
            syntax_errors.append({
                'file': file_path,
                'line': 'N/A',
                'error': f'Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {str(e)}'
            })
    
    print(f"  âœ… Ù…Ù„ÙØ§Øª Ø³Ù„ÙŠÙ…Ø©: {len(valid_files)}")
    print(f"  âŒ Ù…Ù„ÙØ§Øª Ø¨Ù‡Ø§ Ø£Ø®Ø·Ø§Ø¡: {len(syntax_errors)}")
    
    return valid_files, syntax_errors

def analyze_models_file():
    """ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
    print("ğŸ” ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù models.py...")
    
    if not os.path.exists('models.py'):
        return {'error': 'Ù…Ù„Ù models.py ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯'}
    
    try:
        with open('models.py', 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        models = re.findall(r'class\s+(\w+)\(db\.Model\):', content)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª
        relationships = re.findall(r'(\w+)\s*=\s*db\.relationship\([^)]+\)', content)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
        backref_pattern = r"backref='([^']+)'"
        backrefs = re.findall(backref_pattern, content)
        backref_counts = Counter(backrefs)
        duplicate_backrefs = {k: v for k, v in backref_counts.items() if v > 1}
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£Ø³Ø·Ø±
        lines = len(content.split('\n'))
        
        analysis = {
            'models_count': len(models),
            'models': models,
            'relationships_count': len(relationships),
            'duplicate_backrefs': duplicate_backrefs,
            'total_lines': lines,
            'file_size': len(content)
        }
        
        print(f"  ğŸ“Š Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {len(models)}")
        print(f"  ğŸ”— Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª: {len(relationships)}")
        print(f"  âš ï¸ Ø¹Ù„Ø§Ù‚Ø§Øª Ù…ÙƒØ±Ø±Ø©: {len(duplicate_backrefs)}")
        
        return analysis
        
    except Exception as e:
        return {'error': f'Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ models.py: {str(e)}'}

def check_core_files():
    """ÙØ­Øµ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"""
    print("ğŸ” ÙØ­Øµ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©...")
    
    core_files = {
        'app.py': 'Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ',
        'models.py': 'Ù†Ù…Ø§Ø°Ø¬ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª',
        'database.py': 'Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª',
        'requirements.txt': 'Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…',
        '.env': 'Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©'
    }
    
    file_status = {}
    
    for file_path, description in core_files.items():
        if os.path.exists(file_path):
            size = os.path.getsize(file_path)
            file_status[file_path] = {
                'exists': True,
                'size': size,
                'description': description
            }
            print(f"  âœ… {file_path}: {size:,} Ø¨Ø§ÙŠØª")
        else:
            file_status[file_path] = {
                'exists': False,
                'size': 0,
                'description': description
            }
            print(f"  âŒ {file_path}: ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
    
    return file_status

def check_directories():
    """ÙØ­Øµ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©"""
    print("ğŸ” ÙØ­Øµ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª...")
    
    important_dirs = ['static', 'templates', 'uploads']
    dir_status = {}
    
    for dir_name in important_dirs:
        if os.path.exists(dir_name):
            files_count = len([f for f in os.listdir(dir_name) if os.path.isfile(os.path.join(dir_name, f))])
            subdirs_count = len([d for d in os.listdir(dir_name) if os.path.isdir(os.path.join(dir_name, d))])
            
            dir_status[dir_name] = {
                'exists': True,
                'files': files_count,
                'subdirs': subdirs_count
            }
            print(f"  âœ… {dir_name}: {files_count} Ù…Ù„ÙØŒ {subdirs_count} Ù…Ø¬Ù„Ø¯ ÙØ±Ø¹ÙŠ")
        else:
            dir_status[dir_name] = {
                'exists': False,
                'files': 0,
                'subdirs': 0
            }
            print(f"  âŒ {dir_name}: ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
    
    return dir_status

def analyze_database():
    """ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    print("ğŸ” ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    
    db_files = [f for f in os.listdir('.') if f.endswith(('.db', '.sqlite', '.sqlite3'))]
    
    if not db_files:
        print("  âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        return {'exists': False}
    
    db_info = {}
    for db_file in db_files:
        size = os.path.getsize(db_file)
        db_info[db_file] = {
            'size': size,
            'exists': True
        }
        print(f"  âœ… {db_file}: {size:,} Ø¨Ø§ÙŠØª")
    
    return db_info

def count_code_statistics():
    """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙƒÙˆØ¯"""
    print("ğŸ” Ø­Ø³Ø§Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙƒÙˆØ¯...")
    
    python_files = [f for f in os.listdir('.') if f.endswith('.py')]
    
    total_lines = 0
    total_files = len(python_files)
    total_size = 0
    
    file_details = []
    
    for file_path in python_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = len(content.split('\n'))
            size = len(content)
            
            total_lines += lines
            total_size += size
            
            file_details.append({
                'file': file_path,
                'lines': lines,
                'size': size
            })
            
        except Exception:
            continue
    
    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ù„ÙØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ø­Ø¬Ù…
    file_details.sort(key=lambda x: x['size'], reverse=True)
    
    print(f"  ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª: {total_files}")
    print(f"  ğŸ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø³Ø·Ø±: {total_lines:,}")
    print(f"  ğŸ’¾ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­Ø¬Ù…: {total_size:,} Ø¨Ø§ÙŠØª")
    
    return {
        'total_files': total_files,
        'total_lines': total_lines,
        'total_size': total_size,
        'largest_files': file_details[:10]  # Ø£ÙƒØ¨Ø± 10 Ù…Ù„ÙØ§Øª
    }

def generate_system_score():
    """Ø­Ø³Ø§Ø¨ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
    score = 100
    issues = []
    
    # ÙØ­Øµ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    core_files = check_core_files()
    missing_core = sum(1 for f in core_files.values() if not f['exists'])
    if missing_core > 0:
        score -= missing_core * 15
        issues.append(f"Ù…Ù„ÙØ§Øª Ø£Ø³Ø§Ø³ÙŠØ© Ù…ÙÙ‚ÙˆØ¯Ø©: {missing_core}")
    
    # ÙØ­Øµ Ø£Ø®Ø·Ø§Ø¡ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ù…Ù„Ø©
    valid_files, syntax_errors = check_syntax_errors()
    if syntax_errors:
        score -= len(syntax_errors) * 10
        issues.append(f"Ø£Ø®Ø·Ø§Ø¡ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ù…Ù„Ø©: {len(syntax_errors)}")
    
    # ÙØ­Øµ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    models_analysis = analyze_models_file()
    if 'error' in models_analysis:
        score -= 20
        issues.append("Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ù…Ù„Ù Ø§Ù„Ù†Ù…Ø§Ø°Ø¬")
    elif models_analysis.get('duplicate_backrefs'):
        score -= len(models_analysis['duplicate_backrefs']) * 5
        issues.append(f"Ø¹Ù„Ø§Ù‚Ø§Øª Ù…ÙƒØ±Ø±Ø©: {len(models_analysis['duplicate_backrefs'])}")
    
    score = max(0, score)  # Ù„Ø§ ØªÙ‚Ù„ Ø¹Ù† ØµÙØ±
    
    return score, issues

def create_detailed_report():
    """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…ÙØµÙ„"""
    print("=" * 80)
    print("ğŸ“‹ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„ - Ù†Ø¸Ø§Ù… ERP Ù…Ø±Ø§ÙƒØ² Ø§Ù„Ø£ÙˆØ§Ø¦Ù„")
    print("=" * 80)
    print(f"ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¹Ø§Ù…Ø©
    score, issues = generate_system_score()
    
    print(f"\nğŸ¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¹Ø§Ù…Ø©: {score}/100")
    
    if score >= 90:
        status = "Ù…Ù…ØªØ§Ø² ğŸ‰"
    elif score >= 75:
        status = "Ø¬ÙŠØ¯ Ø¬Ø¯Ø§Ù‹ âœ…"
    elif score >= 60:
        status = "Ø¬ÙŠØ¯ âš ï¸"
    else:
        status = "ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† âŒ"
    
    print(f"ğŸ“Š Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {status}")
    
    # ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙØ­Øµ
    print(f"\n" + "=" * 50)
    print("ğŸ“‹ ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙØ­Øµ")
    print("=" * 50)
    
    # 1. ÙØ­Øµ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ù…Ù„Ø©
    valid_files, syntax_errors = check_syntax_errors()
    
    # 2. ÙØ­Øµ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    core_files = check_core_files()
    
    # 3. ÙØ­Øµ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
    directories = check_directories()
    
    # 4. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    models_analysis = analyze_models_file()
    
    # 5. ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    database_info = analyze_database()
    
    # 6. Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙƒÙˆØ¯
    code_stats = count_code_statistics()
    
    # Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„
    if issues:
        print(f"\nâŒ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
        for issue in issues:
            print(f"  - {issue}")
    
    if syntax_errors:
        print(f"\nğŸ” ØªÙØ§ØµÙŠÙ„ Ø£Ø®Ø·Ø§Ø¡ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ù…Ù„Ø©:")
        for error in syntax_errors[:5]:  # Ø£ÙˆÙ„ 5 Ø£Ø®Ø·Ø§Ø¡
            print(f"  - {error['file']}: Ø§Ù„Ø³Ø·Ø± {error['line']} - {error['error']}")
    
    # Ø§Ù„ØªÙˆØµÙŠØ§Øª
    print(f"\nğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª:")
    
    if syntax_errors:
        print(f"  ğŸ”´ Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©: Ø¥ØµÙ„Ø§Ø­ {len(syntax_errors)} Ø®Ø·Ø£ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ù…Ù„Ø©")
    
    if models_analysis.get('duplicate_backrefs'):
        print(f"  ğŸ”´ Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©: Ø¥ØµÙ„Ø§Ø­ {len(models_analysis['duplicate_backrefs'])} Ø¹Ù„Ø§Ù‚Ø© Ù…ÙƒØ±Ø±Ø©")
    
    missing_core = sum(1 for f in core_files.values() if not f['exists'])
    if missing_core > 0:
        print(f"  ğŸŸ¡ Ù…ØªÙˆØ³Ø·Ø© Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©: Ø¥Ù†Ø´Ø§Ø¡ {missing_core} Ù…Ù„Ù Ø£Ø³Ø§Ø³ÙŠ Ù…ÙÙ‚ÙˆØ¯")
    
    missing_dirs = sum(1 for d in directories.values() if not d['exists'])
    if missing_dirs > 0:
        print(f"  ğŸŸ¢ Ù…Ù†Ø®ÙØ¶Ø© Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©: Ø¥Ù†Ø´Ø§Ø¡ {missing_dirs} Ù…Ø¬Ù„Ø¯ Ù…ÙÙ‚ÙˆØ¯")
    
    if score >= 90:
        print(f"  âœ… Ø§Ù„Ù†Ø¸Ø§Ù… ÙÙŠ Ø­Ø§Ù„Ø© Ù…Ù…ØªØ§Ø²Ø©!")
    
    # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ Ù…Ù„Ù
    report_content = f"""
ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„ - Ù†Ø¸Ø§Ù… ERP Ù…Ø±Ø§ÙƒØ² Ø§Ù„Ø£ÙˆØ§Ø¦Ù„
=============================================
ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¹Ø§Ù…Ø©: {score}/100
Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {status}

Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©:
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù…Ù„ÙØ§Øª Python: {code_stats['total_files']}
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø³Ø·Ø±: {code_stats['total_lines']:,}
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­Ø¬Ù…: {code_stats['total_size']:,} Ø¨Ø§ÙŠØª
- Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {models_analysis.get('models_count', 0)}
- Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª: {models_analysis.get('relationships_count', 0)}

Ø§Ù„Ù…Ø´Ø§ÙƒÙ„:
{chr(10).join(f'- {issue}' for issue in issues) if issues else 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø´Ø§ÙƒÙ„ Ø­Ø±Ø¬Ø©'}

Ø£Ø®Ø·Ø§Ø¡ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ù…Ù„Ø©:
{chr(10).join(f'- {error["file"]}: Ø§Ù„Ø³Ø·Ø± {error["line"]} - {error["error"]}' for error in syntax_errors) if syntax_errors else 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø®Ø·Ø§Ø¡'}

Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:
{chr(10).join(f'- {file}: {"Ù…ÙˆØ¬ÙˆØ¯" if info["exists"] else "Ù…ÙÙ‚ÙˆØ¯"}' for file, info in core_files.items())}

Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª:
{chr(10).join(f'- {dir_name}: {"Ù…ÙˆØ¬ÙˆØ¯" if info["exists"] else "Ù…ÙÙ‚ÙˆØ¯"}' for dir_name, info in directories.items())}
"""
    
    with open('system_report.txt', 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…ÙØµÙ„ ÙÙŠ: system_report.txt")
    
    return {
        'score': score,
        'status': status,
        'issues': issues,
        'syntax_errors': len(syntax_errors),
        'models_count': models_analysis.get('models_count', 0),
        'total_files': code_stats['total_files']
    }

if __name__ == "__main__":
    report = create_detailed_report()
    print(f"\nğŸ‰ ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ù†Ø¸Ø§Ù…!")
